<script src="dist/sigprop.js"></script>
<script>
  var sp = sigprop.default; // FIXME.

  console.log("sigprop", sigprop);
  var r = sp(5).mul(5);
  console.assert(!r.inGPU());
  console.log("expect 25. actual:", r.toNumber());
  console.assert(25 == r.toNumber());

  var g = r.gpu();
  console.log("g inGPU", g.inGPU())
  console.assert(g.inGPU());

  let x = g.add(g);
  console.assert(x.inGPU() == true, "x should be in gpu before .toNumber()");
  console.log("x inGPU", x.inGPU())
  console.log("expect 50, actual:", x.toNumber());
  console.assert(50 == x.toNumber());
  // TODO I am documenting the behavior as it is currently implemented.
  // However, my inclination is that x should still be on GPU even after
  // calling getValues() on its NDArray.
  // Here is where the ndarray trashes its GPU memory https://git.io/vFu2v
  // This should probably be changed.
  console.assert(x.inGPU() == false, "x should be in CPU after toNumber()");
</script>
